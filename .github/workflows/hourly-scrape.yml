name: Hourly Scrape

on:
  workflow_dispatch:
  schedule:
    - cron: "0 * * * *"

jobs:
  scrape:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v2

      - name: Fetch database
        env:
          ACCESS_TOKEN: ${{ secrets.ACCESS_TOKEN }}
        run: |
           gh auth login --with-token <<<$ACCESS_TOKEN
           asset=$(gh api /repos/codefodder/hacker-news-digest/actions/artifacts --jq ".artifacts[0] .archive_download_url")
           curl -L -o artifact.zip "$asset" \
           -H "Accept: application/vnd.github.v3+json" \
           -H "Authorization: Bearer $ACCESS_TOKEN"
           unzip artifact.zip

      - name: Install dependencies
        run: pip install -r requirements.txt

      - name: Scrape Hacker News
        run: python hn-hourly-scrape.py

      - name: Review database
        run: sqlite3 hn.db "SELECT datetime, title, link, score, comment_url, comment_count FROM stories ORDER BY datetime DESC;"

      - name: Upload database artifact
        uses: actions/upload-artifact@v2
        with:
          name: hackernews-database
          path: hn.db
