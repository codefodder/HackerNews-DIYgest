name: Hourly Scrape

on:
  workflow_dispatch:
  schedule:
    - cron: "0 * * * *"

jobs:
  scrape:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v2

      - name: Fetch database
        env:
          ACCESS_TOKEN: ${{ secrets.ACCESS_TOKEN }}
        run: |
           gh auth login --with-token <<<$ACCESS_TOKEN
           asset=$(gh api /repos/codefodder/hacker-news-digest/actions/artifacts --jq ".artifacts[0] .archive_download_url")
           curl -L -s -o artifact.zip "$asset" \
           -H "Accept: application/vnd.github.v3+json" \
           -H "Authorization: Bearer $ACCESS_TOKEN"
           unzip artifact.zip

      - name: Install scrape dependencies
        run: |
          pip install -r requirements.txt

      - name: Scrape Hacker News
        run: bin/hn-hourly-scrape.py

      - name: Review database
        run: |
          sqlite3 hn.db < stories.sql

      - name: Install markdown dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y markdown

      - name: Compose email
        run: bin/compose-email.sh

      - name: Email HackerNews DIYgest
        # if: ${{ env.SEND_MAIL == 'true' }}
        uses: dawidd6/action-send-mail@v3
        with:
          subject: HackerNews DIYgest
          from: HackerNews DIYgest
          to: ${{secrets.GMAIL_USER}}
          username: ${{secrets.GMAIL_USER}}
          password: ${{secrets.GM_APPWRD}}
          body: file://stories.md # plaintext
          html_body: file://digest.html
          server_address: smtp.gmail.com
          server_port: 465
          secure: true
          ignore_cert: true
          priority: high

      - name: Upload database artifact
        uses: actions/upload-artifact@v2
        with:
          name: hackernews-database
          path: hn.db
